---
layout: article
title: "[PEFT] Basic PEFT"
date: 2024-12-28 16:01 +0900
category: Lightweighting_Optimization
tags: [Lightweighting & Optimization]
aside:
  toc: true
sidebar:
  nav: lightweighting
---
## Transfer Learning(전이 학습)

- Transfer Learning은 이미 학습이 완료된 모델을 사용하여 **새로운 작업을 위한 데이터로 재학습** 시키는 방법으로 처음부터 학습시키는 것보다 빠르고 쉬운 방법이다.
- Transfer Learning의 대표적인 방법론이 **Fine-Tunning**이다.
- 보통 Pre-train된 모델들은 내가 풀고자 하는 문제에 대한 능력이 부족한 경우가 많다.
- 그렇기에 Fine-Tunning을 통하여 내가 풀고자 하는 작업의 해결 능력을 얻을 수 있게 재학습 하는 것이다.
- Fine-Tunning은 우선 **1)사전 학습된 모델을 선택**하고, 새로운 작업에 맞게 **2)모델의 구조를 조정** 한 뒤에 사전 학습된 가중치를 사용하여 새로운 데이터 셋으로 **3)재학습**하는 과정으로 이뤄진다.

## PEFT(Parameter-Efficient Fine-Tuning)

- 최근 대부분의 모델들이 사이즈가 커짐에 따라 Fine-Tunning 시에 드는 시간과 자원이 굉장히 많이 증가했다.
- 이를 위해 나온 것이 PEFT로 Fine-Tunning과 달리 모델의 전체 파라미터를 재학습하는 것이 아닌 **일부분을 학습하도록 하는 방법**이다.
- PEFT는 크게 **프롬프트 튜닝 방식**과 **파라미터 삽입 방식**이 있다.
- 프롬프트 튜닝 방식은 **모델의 원래 파라미터와 프롬프트를 변경하지 않고 추가적인 프롬프트를 추가하여 학습하는 방식**으로 추가된 프롬프트가 원래 프롬프트와 상호작용을 통해 **모델의 출력을 원하는 방향으로 유도**하게 한다.
- 파라미터 삽입 방식은 **모델의 특정 위치에 추가적으로 파라미터를 삽입**하여 모델을 Fine-Tunning하는 것이다. 대표적으로 Adapter, LoRA 등의 방식이 있다.

## Adapter

- 파라미터 삽입 방식 중 하나로 **기존 pre-train된 모델의 layer 사이에 Adapter라는 모듈을 삽입**하는 방식이다.
    
    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/6acf52cb-2c5c-462e-bf26-b7011fa2da60/18e0430c-6cba-40a2-9100-33d1590faec3/image.png)
    
- 위의 그림과 같은 모듈을 layer 사이에 모듈을 넣어주는 것을 볼 수 있다.
- 추가되는 모듈을 보면 **Skip-Connection**을 사용하고, **Bottleneck** 구조라고 한다.
- 여기에서  Reparameterization Trick인 **Low-Rank Decomposition**을 사용하여 FNN의 Weigth의 파라미터 수를 줄인다.

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/6acf52cb-2c5c-462e-bf26-b7011fa2da60/5e819be6-773a-4be6-81bd-776e21eee6e9/image.png)

- 예를 들어, x가 (1 x 300), W가 (300 x 300)이라고 가정해보자.
- Trick없이 그냥 진행하게 되면 총 90000개의 파라미터가 필요해 진다.
- 하지만 위의 그림처럼 W를 2개의 Low-Rank의 행렬로 나누게 되어 계산을 하게 되면 2 * (300 * r)개의 파라미터만 사용하면 된다.(Low-Rank니까 r이 당연히 작음)
- 또한 이를 통해 우리가 필요한 파라미터 수를 조절할 수도 있다.

## LoRA(Low-Rank Adaptation)

- Adapter와 달리 직렬적으로 배치하는 것이 아닌 **병렬적으로 위치 시키는 것**이다. 또한 **비선형 함수와 Bias를 사용하지 않아** 속도 측면에서 Adapter보다 효율적이다.
    
    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/6acf52cb-2c5c-462e-bf26-b7011fa2da60/5f75ae05-8cb3-4a8a-ab0e-b1dcb4c4b9ae/image.png)
    
- Adapter와 마찬가지로 **Reparameterization Trick**을 사용한다. 결국 Adapter와 다른 점은 **1)비선형 함수 사용 유무**, **2) Bias 학습 유무**, **3)직렬적인지 병렬적인지** 이다.
- 비선형 함수를 사용하지 않으면 유의미한 Decision Boundary를 만들 수 있을까?
    - 논문에서 말하기에는 이미 Pretrain된 모델에서 비선형 함수가 학습하고 있기에 괜찮다고 말하고, 실험적으로도 증명을 했다.
- **Adapter vs. LoRA**

|  | **Adapter** | **LoRA** |
| --- | --- | --- |
| **모듈 연산 방법** | 직렬적 연산 | 병렬적 연산 |
| **비선형 함수** | 사용 O | 사용 X |
| **학습 파라미터** | Weight, Bias | Weight |
| **연산 지연** | 모듈에 비례하여 발생 | 거의 발생 X |